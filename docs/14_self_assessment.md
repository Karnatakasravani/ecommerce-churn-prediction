ğŸ“˜ Self-Assessment Report

Project Completion



This project implements an end-to-end churn prediction system using the UCI Online Retail dataset including data cleaning, feature engineering, modeling, evaluation, deployment via Streamlit, and documentation.



âœ… Phase-wise Completion

Phase	Status	Score (Self)	Comments

1\. Business Understanding	Complete	9/10	Clearly understood churn problem and business objective

2\. Data Acquisition	Complete	14/15	Successfully loaded \& validated dataset

3\. Data Cleaning	Complete	14/15	Missing values handled, invalid rows removed

4\. Feature Engineering	Complete	14/15	Created ~25+ meaningful customer-level features

5\. Churn Definition \& Splitting	Complete	8/10	Time-based churn definition implemented

6\. Modeling \& Evaluation	Complete	13/15	Random Forest achieved strong ROC-AUC

7\. Deployment	Complete	8/10	Streamlit app deployed successfully

8\. Documentation \& Reporting	Complete	8/10	All required docs + submission metadata created



Total Self-Score: 88 / 100



ğŸŒŸ Key Achievements



Built a complete end-to-end ML pipeline from raw data to deployed model



Successfully deployed a live Streamlit application for churn prediction



Designed meaningful customer-behavior features improving model accuracy



ğŸ§  Challenges Overcome



Challenge: Handling missing CustomerID and cleaning noisy transaction data

Solution:



* Removed rows with missing customer IDs



* Filtered invalid/negative quantities



* Ensured chronological order for churn labeling



Learning:

I learned the importance of clean data and consistent time-based logic when defining churn.



ğŸ” Areas for Improvement



Could experiment with more model tuning \& explainability



Would like to automate pipeline execution



Could improve UI further for production-style usage



â± Time Spent

Task-Hours

1. Data Cleaning-6
2. Feature Engineering-7
3. Modeling-5
4. Deployment-4
5. Documentation-3
   

* Total-25 hours







ğŸ“š Resources Used



* Official Pandas \& Scikit-Learn docs
* Streamlit documentation
* Online tutorials \& references
* Stack Overflow
* Dataset description page



I ensured understanding of all concepts before using any reference.



ğŸ¯ Reflection



This project helped me strengthen:



âœ” applied data science workflow

âœ” real-world problem solving

âœ” deployment skills

âœ” documentation \& communication



I now feel more prepared for real analytics projects.

